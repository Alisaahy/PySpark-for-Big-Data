{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data\n",
    "\n",
    "- Data that can fit on a local computer,  are mostly in the scale of 0-32 GB depending on RAM.\n",
    "- What can we do if we have a larger set of data?\n",
    " - For data size between 30-60 GB, it's still not large enough that you could buy enough RAM to just fit it all in your RAM and you have a quick acess to it.\n",
    " - If you have a larger set of data than you can hold on RAM, you can try using a SQL database to move storage onto hard drive instead of RAM.\n",
    " - Or use a dirtributed system, that distributes the data to multiple machines/computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed system\n",
    "Distributed system: you have on main computer, like some sort of a master node , and you have data and calculation distributed onto the other computers.\n",
    "\n",
    "- What you can do in a local system versus a distributed system is, in you local system, you'll be limited to however many cores on your local system. That is how much processing power or how much storage you have locally.\n",
    "But in a distributed system, you can leverage power of a bunch of weaker machines to eventually have more cores and more capabilities than even a strong local single machine.\n",
    "\n",
    "- It's easier to scale up distributed machines. All you have to do is just adding more machines to the network, and making it more powerful.\n",
    "\n",
    "- Distributed system also include fault tolerance. If one machine fails, the whole network can still go on. You can't do that on your local machine. If your local machine crashes due to some error, you'll just lost all calculations.\n",
    "Fault tolerance is a fundamental idea where you're going to be replicating uour data across multiple machines, so even if one goes down, your calculations and your data still persists and goes on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typical form of a distributed architecture that uses Hadoop\n",
    "\n",
    "- Hadoop is a way to distribute very large files across multiple machines.\n",
    "- It uses the Hadoop Distributed File System (HDFS), which allows a user to work with larger datasets.\n",
    "- HDFS also duplicates blocks of data for fault tolerance. If one machine goes down in your system, your dta is duplicated on some other machines.\n",
    "- It uses MapReduce, which allows computations across the distributed dataset.\n",
    "\n",
    "You have some sort of a master node or a named node, with its own CPU and RAM and that basically controls the process of either distributing the storage or the calculations to other data nodes, which also have their own CPU and own RAM.\n",
    "\n",
    "<img src=\"images/1.png\" width=400>\n",
    "\n",
    "- HDFS uses blocks of data, with a size of 128 MB by default.\n",
    "- Each of these blocks is replicated 3 times to support fault tolerance and prevent loss of data due to a failure of a node.\n",
    "- Smaller blocs provide more parallelization during process.\n",
    "\n",
    "<img src=\"images/2.png\" width=350>\n",
    "\n",
    "- MapReduce is a way of splitting computational tasks to a distributed set of files (such as HDFS).\n",
    "- It consists of a Job Tracker and multiple Task Trackers.\n",
    "- The Job Tracker sends code to run on the Task Trackers and the Task Trackers allocate CPU and memory for the tasks and monitor the tasks on the worker nodes.\n",
    "\n",
    "So basically, we use HDFS to distribute large datasets and MapReduce to distribute a computational task to a distributed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark\n",
    "\n",
    "You can think of Spark as a flexible alternative to MapReduce. \n",
    "- MapReduce requires files to be stored in HDFS, Spark does not. Spark can use data stored in a variety of formats:\n",
    " - Cassandra\n",
    " - AWS S3\n",
    " - HDFS\n",
    " - ...\n",
    "- Spark can perform operations up to 100x faster than MapReduce.\n",
    " - MapReduce writes most data to disk after each map and reduce operation.\n",
    " - Spark keeps most of the data in memory after each transformation instead of writing and reading to the disk.\n",
    " - Spark can spill over to disk if the memory is filled.\n",
    " \n",
    "#### RDD\n",
    "At the core of Spark is the idea of Resilient Distributed Dataset (RDD). RDD has 4 main features:\n",
    "- Distributed Collection of Data\n",
    "- Fault-tolerant\n",
    "- Parallel operation\n",
    "- Ability to use many data sources\n",
    "\n",
    "- RDDs are immutable, lazily evaluated, and cacheable.\n",
    "- There're 2 types of Spark operations:\n",
    " - Transformations: transformations are basically a recipe to follow\n",
    " - Actions: actions actually what the recipe says to do and returns something back.\n",
    " > This behavior carries over the syntax when coding. A lot of times you'll write a method call, but won't see anything as a result until you call the action. This makes sense because with a large dataset, you don't want to calculate all the transformations untill you're sure you want to perform them.\n",
    " \n",
    "> Currently, Spark is moving towards a DataFrame based syntax, but that the way files are being distributed is still RDD. It's just the typed out syntax that's changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
